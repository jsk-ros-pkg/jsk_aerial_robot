{
  "total_losses": {
    "train": [
      1.27569441279555,
      0.15527114314355686,
      0.14035869149466926,
      0.13933707008120474,
      0.15533426713898185,
      0.2052016320074133,
      0.17426909205374713,
      0.2211095793070373,
      0.17312504214936608,
      0.24966510654083454,
      0.14530812418900366,
      0.1704602408576463,
      0.14490215245875734,
      0.13805448684733904,
      0.1378724037303169,
      0.13725125502756347,
      0.13716831357526577,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN
    ],
    "val": [
      0.1431014336292854,
      0.14297585746395253,
      0.14196983773727687,
      0.14105674361985507,
      0.14157138439961817,
      0.14032307067782504,
      0.14118726108798235,
      0.14040504915214508,
      0.14132572169147553,
      0.14063766112504608,
      0.14104004741584275,
      0.14045381286776726,
      0.14190956959982018,
      0.141523568062392,
      0.14128404536876663,
      0.14117263007747988,
      0.1412435187838143,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN,
      NaN
    ]
  },
  "inference_times": [
    0.1788616180419922,
    0.11487007141113281,
    0.1555919647216797,
    0.1723766326904297,
    0.10180473327636719,
    0.11992454528808594,
    0.16393661499023438,
    0.1324176788330078,
    0.13251304626464844,
    0.10638236999511719,
    0.11854171752929688,
    0.10595321655273438,
    0.11186599731445312,
    0.1377105712890625,
    0.1540660858154297,
    0.09794235229492188,
    0.10285377502441406,
    0.10938644409179688,
    0.09756088256835938,
    0.10051727294921875,
    0.14171600341796875,
    0.14600753784179688,
    0.10061264038085938,
    0.14090538024902344,
    0.11792182922363281,
    0.10275840759277344,
    0.11248588562011719,
    0.10166168212890625,
    0.16150474548339844,
    0.10852813720703125,
    0.12340545654296875,
    0.11582374572753906,
    0.09403228759765625,
    0.12063980102539062,
    0.09889602661132812,
    0.14858245849609375,
    0.11415481567382812,
    0.09684562683105469,
    0.10738372802734375,
    0.1224994659423828,
    0.10104179382324219,
    0.10251998901367188,
    0.1575946807861328,
    0.09560585021972656,
    0.11744499206542969,
    0.10228157043457031,
    0.11153221130371094,
    0.10523796081542969,
    0.09469985961914062,
    0.10285377502441406,
    0.31719207763671875,
    0.14963150024414062,
    0.09822845458984375,
    0.10995864868164062,
    0.10151863098144531,
    0.10523796081542969,
    0.1209259033203125,
    0.1384735107421875,
    0.10294914245605469,
    0.10519027709960938,
    0.12764930725097656,
    0.10318756103515625,
    0.1633167266845703,
    0.11043548583984375,
    0.14395713806152344,
    0.12211799621582033,
    0.09641647338867188,
    0.10881423950195312,
    0.11487007141113281,
    0.10242462158203125,
    0.12030601501464844,
    0.11973381042480469,
    0.16756057739257812,
    0.09932518005371094,
    0.109100341796875,
    0.17876625061035156,
    0.09593963623046875,
    0.1357555389404297,
    0.09617805480957031,
    0.1064300537109375,
    0.148773193359375,
    0.12283325195312501,
    0.11625289916992188,
    0.09632110595703125,
    0.11262893676757812,
    0.09789466857910156,
    0.13494491577148438,
    0.09937286376953125,
    0.167083740234375,
    0.13289451599121094,
    0.10585784912109375,
    0.11377334594726562,
    0.09794235229492188,
    0.1560211181640625,
    0.10476112365722656,
    0.1667022705078125,
    0.2254486083984375,
    0.10967254638671875,
    0.13790130615234375,
    0.12679100036621094,
    0.12478828430175781,
    0.10962486267089844,
    0.14710426330566406,
    0.11949539184570312,
    0.14052391052246094,
    0.104522705078125,
    0.1087188720703125,
    0.10828971862792969,
    0.109100341796875,
    0.1399993896484375,
    0.09584426879882812,
    0.10561943054199219,
    0.09608268737792969,
    0.10762214660644531,
    0.10371208190917969,
    0.11391639709472656,
    0.0988006591796875,
    0.154876708984375,
    0.11243820190429688,
    0.10218620300292969,
    0.1636505126953125,
    0.10075569152832031,
    0.09865760803222656,
    0.10170936584472656,
    0.15625953674316406,
    0.12083053588867188,
    0.11239051818847656,
    0.11873245239257812,
    0.1102447509765625,
    0.14286041259765625,
    0.10838508605957031,
    0.09698867797851562,
    0.1636028289794922,
    0.12159347534179688,
    0.11248588562011719,
    0.10547637939453125,
    0.106048583984375,
    0.10142326354980469,
    0.13980865478515625,
    0.10027885437011719,
    0.14553070068359375,
    0.1259326934814453,
    0.10552406311035156,
    0.10333061218261719,
    0.10204315185546875,
    0.1254558563232422,
    0.1259326934814453,
    0.10552406311035156,
    0.1533985137939453,
    0.10166168212890625
  ],
  "learning_rates": [
    0.00095,
    0.0009025,
    0.000857375,
    0.0008145062499999999,
    0.0007737809374999998,
    0.0007350918906249999,
    0.0006983372960937497,
    0.0006634204312890623,
    0.0006302494097246091,
    0.0005987369392383787,
    0.0005688000922764596,
    0.0005403600876626366,
    0.0005133420832795048,
    0.00048767497911552955,
    0.000463291230159753,
    0.00044012666865176535,
    0.0004181203352191771,
    0.0003972143184582182,
    0.00037735360253530727,
    0.0003584859224085419,
    0.0003405616262881148,
    0.000323533544973709,
    0.00030735686772502356,
    0.0002919890243387724,
    0.00027738957312183375,
    0.00026352009446574203,
    0.00025034408974245495,
    0.00023782688525533216,
    0.00022593554099256555,
    0.00021463876394293727,
    0.00020390682574579038,
    0.00019371148445850088,
    0.00018402591023557584,
    0.000174824614723797,
    0.00016608338398760718,
    0.0001577792147882268,
    0.00014989025404881545,
    0.00014239574134637466,
    0.00013527595427905592,
    0.00012851215656510312,
    0.00012208654873684796,
    0.00011598222130000556,
    0.00011018311023500529,
    0.00010467395472325501,
    9.944025698709225e-05,
    9.446824413773763e-05,
    8.974483193085076e-05,
    8.52575903343082e-05,
    8.099471081759279e-05,
    7.694497527671315e-05,
    7.30977265128775e-05,
    6.94428401872336e-05,
    6.597069817787194e-05,
    6.267216326897833e-05,
    5.953855510552941e-05,
    5.656162735025293e-05,
    5.373354598274029e-05,
    5.1046868683603266e-05,
    4.8494525249423105e-05,
    4.6069798986951947e-05,
    4.3766309037604346e-05,
    4.157799358572413e-05,
    3.949909390643792e-05,
    3.752413921111602e-05,
    3.564793225056022e-05,
    3.386553563803221e-05,
    3.217225885613059e-05,
    3.0563645913324066e-05,
    2.903546361765786e-05,
    2.7583690436774966e-05,
    2.6204505914936218e-05,
    2.4894280619189404e-05,
    2.3649566588229933e-05,
    2.2467088258818436e-05,
    2.134373384587751e-05,
    2.0276547153583635e-05,
    1.9262719795904453e-05,
    1.8299583806109228e-05,
    1.7384604615803768e-05,
    1.651537438501358e-05,
    1.56896056657629e-05,
    1.4905125382474753e-05,
    1.4159869113351015e-05,
    1.3451875657683464e-05,
    1.2779281874799288e-05,
    1.2140317781059324e-05,
    1.1533301892006358e-05,
    1.095663679740604e-05,
    1.0408804957535738e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05,
    1e-05
  ],
  "model_config": {
    "NetworkConfig": {
      "model_name": "residual_mlp",
      "delay_horizon": 0,
      "hidden_sizes": [
        64,
        64
      ],
      "activation": "GELU",
      "use_batch_norm": false,
      "dropout_p": 0.0,
      "num_epochs": 150,
      "batch_size": 64,
      "loss_weight": [
        1.0,
        1.0,
        1.0
      ],
      "optimizer": "Adam",
      "weight_decay": 0.001,
      "l1_lambda": 0.0,
      "gradient_lambda": 10000.0,
      "consistency_lambda": 5.0,
      "consistency_epsilon": 0.3,
      "symmetry_lambda": 0.001,
      "learning_rate": 0.001,
      "lr_scheduler": "LambdaLR",
      "num_workers": 0
    },
    "ModelFitConfig": {
      "control_averaging": false,
      "use_low_pass_filter": false,
      "low_pass_filter_cutoff_input": 1.0,
      "low_pass_filter_cutoff_label": 0.1,
      "use_moving_average_filter": true,
      "window_size": 5,
      "label_transform": false,
      "input_transform": false,
      "prune": false,
      "histogram_n_bins": 10,
      "histogram_thresh": 0.001,
      "vel_cap": 16,
      "plot_dataset": false,
      "save_plots": false,
      "ds_name": "NMPCTiltQdServo_real_machine_dataset_FULL",
      "ds_instance": "dataset_001",
      "state_feats": [
        2
      ],
      "u_feats": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7
      ],
      "y_reg_dims": [
        3,
        4,
        5
      ]
    }
  }
}
